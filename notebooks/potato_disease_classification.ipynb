{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004d20ea",
   "metadata": {},
   "source": [
    "# Potato Disease Classification\n",
    "## Machine Learning Pipeline - Summative Project\n",
    "\n",
    "**Author:** Edine Noella Mugisha \n",
    "\n",
    "**Date:** November 2024  \n",
    "**Objective:** Build an end-to-end ML pipeline for classifying potato leaf diseases\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Statement\n",
    "Small-scale farmers in Africa lose 30-50% of their potato crop yield to diseases annually. The two main diseases affecting potatoes are:\n",
    "\n",
    "1. **Early Blight** (Alternaria solani)\n",
    "2. **Late Blight** (Phytophthora infestans)\n",
    "\n",
    "### Solution\n",
    "Build an AI-powered image classification system to:\n",
    "- Detect diseases early from leaf images\n",
    "- Provide instant diagnosis with confidence scores\n",
    "- Offer treatment recommendations\n",
    "- Enable accessible expert diagnosis\n",
    "\n",
    "### Dataset\n",
    "- **Source:** PlantVillage Dataset (https://github.com/spMohanty/PlantVillage-Dataset)\n",
    "- **Classes:** 3 (Early Blight, Late Blight, Healthy)\n",
    "- **Total Images:** 2,152\n",
    "- **Format:** JPG, RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcc297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n",
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "#-------------------\n",
    "\n",
    "# Core Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Data Download\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c35bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA ACQUISITION\n",
      "================================================================================\n",
      "Downloading PlantVillage dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/spMohanty/PlantVillage-Dataset/archive/master.zip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m zip_path = os.path.join(data_root, \u001b[33m'\u001b[39m\u001b[33mplantvillage.zip\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Extract into data_root\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(zip_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:242\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[32m    240\u001b[39m     reporthook(blocknum, bs, size)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m block := \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    243\u001b[39m     read += \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[32m    244\u001b[39m     tfp.write(block)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:473\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt >= \u001b[32m0\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:599\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left := \u001b[38;5;28mself\u001b[39m._get_chunk_left()) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt <= chunk_left:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m         value.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    600\u001b[39m         \u001b[38;5;28mself\u001b[39m.chunk_left = chunk_left - amt\n\u001b[32m    601\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:642\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    637\u001b[39m \n\u001b[32m    638\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    644\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Data Acquisition\n",
    "#-----------------\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA ACQUISITION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Root of your project (optional: you can hardcode if you prefer)\n",
    "project_dir = '/Users/edine.mugisha/Documents/School/potato_disease_summative_MLOP'\n",
    "\n",
    "# Data folder\n",
    "data_root = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Dataset folder (this is the folder you manually put there)\n",
    "dataset_dir = os.path.join(data_root, 'PlantVillage-Dataset-master')\n",
    "\n",
    "# Check that the dataset folder exists\n",
    "if not os.path.exists(dataset_dir):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset folder not found at:\\n  {dataset_dir}\\n\"\n",
    "        \"Make sure you downloaded and unzipped the PlantVillage repo into the 'data' folder.\"\n",
    "    )\n",
    "\n",
    "print(f\"✓ Dataset folder found at: {dataset_dir}\")\n",
    "\n",
    "# Base path where class folders live\n",
    "base_path = os.path.join(dataset_dir, 'raw', 'color')\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"'raw/color' folder not found inside dataset folder:\\n  {base_path}\\n\"\n",
    "        \"Check that the folder structure matches: PlantVillage-Dataset-master/raw/color/...\"\n",
    "    )\n",
    "\n",
    "# List all available categories\n",
    "all_categories = sorted([\n",
    "    d for d in os.listdir(base_path)\n",
    "    if os.path.isdir(os.path.join(base_path, d))\n",
    "])\n",
    "\n",
    "print(f\"\\n✓ Found {len(all_categories)} categories:\")\n",
    "for c in all_categories:\n",
    "    print(\"  -\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select potato-related categories\n",
    "#---------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SELECTING POTATO DISEASE CLASSES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Focus on potato diseases\n",
    "SELECTED_CLASSES = [\n",
    "    'Potato___Early_blight',\n",
    "    'Potato___Late_blight',\n",
    "    'Potato___healthy'\n",
    "]\n",
    "\n",
    "categories = [cat for cat in all_categories if cat in SELECTED_CLASSES]\n",
    "\n",
    "print(f\"\\n✓ Selected {len(categories)} classes:\")\n",
    "for i, cat in enumerate(categories, 1):\n",
    "    count = len(os.listdir(os.path.join(base_path, cat)))\n",
    "    print(f\"  {i}. {cat}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89de88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Class Distribution\n",
    "#-------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {}\n",
    "for category in categories:\n",
    "    class_path = os.path.join(base_path, category)\n",
    "    class_counts[category] = len(os.listdir(class_path))\n",
    "\n",
    "# Create DataFrame\n",
    "df_counts = pd.DataFrame(list(class_counts.items()), \n",
    "                         columns=['Class', 'Count'])\n",
    "df_counts['Class'] = df_counts['Class'].str.replace('Potato___', '').str.replace('_', ' ')\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df_counts)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot\n",
    "axes[0].bar(df_counts['Class'], df_counts['Count'], \n",
    "           color=['#e74c3c', '#e67e22', '#27ae60'])\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Disease Class')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#e74c3c', '#e67e22', '#27ae60']\n",
    "axes[1].pie(df_counts['Count'], labels=df_counts['Class'], \n",
    "           autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Class Distribution (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Total images: {df_counts['Count'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Sample Images\n",
    "#--------------------\n",
    "\n",
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    class_path = os.path.join(base_path, category)\n",
    "    images = os.listdir(class_path)[:4]\n",
    "    \n",
    "    for j, img_name in enumerate(images):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        axes[i, j].imshow(img)\n",
    "        axes[i, j].axis('off')\n",
    "        if j == 0:\n",
    "            clean_name = category.replace('Potato___', '').replace('_', ' ')\n",
    "            axes[i, j].set_title(clean_name, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_sample_images.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782baa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Properties Analysis\n",
    "#-------------------------\n",
    "\n",
    "# Analyze image properties\n",
    "image_sizes = []\n",
    "aspect_ratios = []\n",
    "\n",
    "for category in categories:\n",
    "    class_path = os.path.join(base_path, category)\n",
    "    images = os.listdir(class_path)[:50]  # Sample 50 images per class\n",
    "    \n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        image_sizes.append((width, height))\n",
    "        aspect_ratios.append(width / height)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Image sizes\n",
    "widths = [s[0] for s in image_sizes]\n",
    "heights = [s[1] for s in image_sizes]\n",
    "axes[0].scatter(widths, heights, alpha=0.5)\n",
    "axes[0].set_title('Image Dimensions Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Width (pixels)')\n",
    "axes[0].set_ylabel('Height (pixels)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Aspect ratios\n",
    "axes[1].hist(aspect_ratios, bins=30, color='steelblue', alpha=0.7)\n",
    "axes[1].set_title('Aspect Ratio Distribution', fontweight='bold')\n",
    "axes[1].set_xlabel('Aspect Ratio')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_image_properties.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Width: {np.mean(widths):.0f} pixels\")\n",
    "print(f\"Average Height: {np.mean(heights):.0f} pixels\")\n",
    "print(f\"Average Aspect Ratio: {np.mean(aspect_ratios):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Setup\n",
    "#-------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Image Size: {IMG_SIZE}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Validation Split: {VALIDATION_SPLIT}\")\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Data augmentation configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "#-----------\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    classes=SELECTED_CLASSES,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    base_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=SELECTED_CLASSES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class information\n",
    "class_indices = train_generator.class_indices\n",
    "class_names = list(class_indices.keys())\n",
    "\n",
    "print(f\"\\n✓ Training samples: {train_generator.samples}\")\n",
    "print(f\"✓ Validation samples: {val_generator.samples}\")\n",
    "print(f\"✓ Number of classes: {len(class_names)}\")\n",
    "print(f\"✓ Class names: {class_names}\")\n",
    "\n",
    "# Save class names\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e199e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Augmentation\n",
    "#-----------------------\n",
    "\n",
    "# Visualize data augmentation\n",
    "def visualize_augmentation(generator, num_samples=9):\n",
    "    # Get a batch\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(images[i])\n",
    "        class_idx = np.argmax(labels[i])\n",
    "        class_name = class_names[class_idx].replace('Potato___', '').replace('_', ' ')\n",
    "        axes[i].set_title(f'{class_name}', fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Augmented Training Images', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('augmented_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building (Custom CNN + Transfer Learning)\n",
    "#-----------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL BUILDING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, \n",
    "                                     BatchNormalization, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_shape = IMG_SIZE + (3,)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Simple baseline CNN built from scratch.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_transfer_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Transfer Learning using MobileNetV2 as feature extractor.\n",
    "    \"\"\"\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model for initial training\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Choose which model to use: \"cnn\" or \"transfer\"\n",
    "MODEL_TYPE = \"transfer\"   # <- change to \"cnn\" if you want the scratch CNN\n",
    "\n",
    "if MODEL_TYPE == \"cnn\":\n",
    "    model = build_cnn_model(input_shape, num_classes)\n",
    "    model_name = \"potato_cnn\"\n",
    "else:\n",
    "    model = build_transfer_model(input_shape, num_classes)\n",
    "    model_name = \"potato_mobilenetv2\"\n",
    "\n",
    "# Compile model\n",
    "learning_rate = 1e-4\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model type: {MODEL_TYPE}\")\n",
    "print(f\"✓ Model name: {model_name}\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup with Callbacks\n",
    "#--------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Make directory for models\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(\"models\", f\"{model_name}_best.h5\")\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_cb, earlystop_cb, reduce_lr_cb]\n",
    "\n",
    "EPOCHS = 20  # you can increase to e.g. 30 if training is stable\n",
    "\n",
    "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
    "validation_steps = val_generator.samples // BATCH_SIZE\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"  Validation steps: {validation_steps}\")\n",
    "print(f\"  Checkpoint path: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "#---------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n✓ Training completed in {training_time/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf71c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training History Visualization\n",
    "#--------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING HISTORY VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convert history to DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(\"\\nHistory keys:\", history_df.columns.tolist())\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy over Epochs', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_accuracy_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss over Epochs', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save history to JSON (for reproducibility)\n",
    "with open(f'{model_name}_history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "print(\"\\n✓ Training curves saved as PNG\")\n",
    "print(\"✓ History saved as JSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23842261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "#-----------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION ON VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ensure we evaluate with the best weights (best checkpoint already restored by EarlyStopping)\n",
    "val_loss, val_acc = model.evaluate(val_generator, verbose=1)\n",
    "print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df320eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report and Accuracy\n",
    "#-----------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED EVALUATION METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Reset generator to start from beginning\n",
    "val_generator.reset()\n",
    "\n",
    "# Get predictions (probabilities)\n",
    "y_prob = model.predict(val_generator, verbose=1)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "# True labels\n",
    "y_true = val_generator.classes\n",
    "target_names = list(val_generator.class_indices.keys())\n",
    "\n",
    "# Overall accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "#------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.title('Confusion Matrix', fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves (One-vs-Rest)\n",
    "#------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROC CURVES (ONE-vs-REST)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Binarize labels\n",
    "y_true_bin = to_categorical(y_true, num_classes=num_classes)\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Micro-average ROC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, class_name in enumerate(target_names):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.title('ROC Curves (One-vs-Rest)', fontweight='bold')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAUC scores per class:\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"  {class_name}: {roc_auc[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efdaee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Predictions\n",
    "#-------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get one batch of validation images\n",
    "val_batch_images, val_batch_labels = next(val_generator)\n",
    "\n",
    "# Get predictions for this batch\n",
    "batch_prob = model.predict(val_batch_images)\n",
    "batch_pred = np.argmax(batch_prob, axis=1)\n",
    "batch_true = np.argmax(val_batch_labels, axis=1)\n",
    "\n",
    "num_samples = 9\n",
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = val_batch_images[i]\n",
    "    true_label = target_names[batch_true[i]]\n",
    "    pred_label = target_names[batch_pred[i]]\n",
    "    confidence = np.max(batch_prob[i]) * 100\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    title_color = 'green' if true_label == pred_label else 'red'\n",
    "    plt.title(\n",
    "        f\"True: {true_label.replace('Potato___', '').replace('_', ' ')}\\n\"\n",
    "        f\"Pred: {pred_label.replace('Potato___', '').replace('_', ' ')} ({confidence:.1f}%)\",\n",
    "        color=title_color,\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.suptitle('Sample Validation Predictions', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Model and Artifacts\n",
    "#-------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING MODEL & ARTIFACTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "export_dir = os.path.join(\"models\", f\"{model_name}_{timestamp}\")\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save Keras .h5 model\n",
    "h5_path = os.path.join(export_dir, f\"{model_name}.h5\")\n",
    "model.save(h5_path)\n",
    "print(f\"✓ Model saved as H5 at: {h5_path}\")\n",
    "\n",
    "# 2. Save TensorFlow SavedModel format\n",
    "savedmodel_path = os.path.join(export_dir, \"saved_model\")\n",
    "model.save(savedmodel_path)\n",
    "print(f\"✓ Model saved in SavedModel format at: {savedmodel_path}\")\n",
    "\n",
    "# 3. Save class names (again, with timestamped path)\n",
    "class_names_path = os.path.join(export_dir, \"class_names.json\")\n",
    "with open(class_names_path, 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "print(f\"✓ Class names saved at: {class_names_path}\")\n",
    "\n",
    "# 4. Save latest history as JSON\n",
    "history_path = os.path.join(export_dir, \"training_history.json\")\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "print(f\"✓ Training history saved at: {history_path}\")\n",
    "\n",
    "print(\"\\nAll artifacts saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Potato ML (venv)",
   "language": "python",
   "name": "potato-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
